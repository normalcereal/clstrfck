Update: tabled until further notice. Prompt hacking born from this one will still likely be quite awesome, repo stays alive for now.
# clstrfck
clstrfck -- a simple encoder that reduces textual english word length using a consistent, static, ruleset. Originally created to reduce the number of tokens used in text generation so as to increase information density in text generation priming and prompting, whilst outputting text that decodes to a significantly greater length than previously possible. First used for fine-tuning in language models, then used for prompting, assuming the language model can -- for the most part -- connect the relativistic linguistic dots for the shorter token lengths in the vocabulary.

# Thoughts

â€“ First round maybe only change words for characters are more by removing vowels and that's it. Then train language model with data set process in the way just mentioned and test.
